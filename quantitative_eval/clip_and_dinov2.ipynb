{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhqbImVPLPV3",
        "outputId": "1f07a985-340f-44da-e221-d60f10196cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "1. download the datasets from our github repo\n",
        "2. upload them into google drive in separate folders\n",
        "3. cd to the parent directories of the uploaded folders"
      ],
      "metadata": {
        "id": "6qBVz5MXiQrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10623/project_eval/clip_report\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNQVGA-_dLMT",
        "outputId": "6bd4325a-a36c-4f92-a4dd-c6f8bde68eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10623/project_eval/clip_report\n",
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/  \u001b[01;34moutput_baseline\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q condacolab\n",
        "# import condacolab\n",
        "# condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2uImOUiUAvb",
        "outputId": "8dc75612-d706-4931-e833-af62bfdea572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For offical pip\n",
        "# !pip install pytorch>1.7.1 torchvision cudatoolkit\n",
        "# !pip install ftfy regex tqdm datasets\n",
        "# !pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# For transformers pip\n",
        "pip install transformers Pillow torch"
      ],
      "metadata": {
        "id": "dISfqy_6TCO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e19433-2c29-4bbd-9356-13f430c3f478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cudatoolkit\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: ftfy in /usr/local/lib/python3.10/site-packages (6.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (2024.4.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (4.66.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/site-packages (2.19.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/site-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/site-packages (from datasets) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/site-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-tbklap9j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-tbklap9j\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/site-packages (from clip==1.0) (6.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/site-packages (from clip==1.0) (2024.4.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from clip==1.0) (2.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/site-packages (from clip==1.0) (0.18.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/site-packages (from torch->clip==1.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From CLIP official"
      ],
      "metadata": {
        "id": "NcxMS9r6KewZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYKnfYgoRhxV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import clip\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "#modified from offical implementation of CLIP: https://github.com/openai/CLIP\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "def calculate_clip(t1, t2, is_multimodal):\n",
        "    t1_input = preprocess(PIL.Image.open(t1)).unsqueeze(0).to(device)\n",
        "\n",
        "    if is_multimodal:\n",
        "        t2_input = clip.tokenize(t2).to(device)\n",
        "    else:\n",
        "        t2_input = preprocess(PIL.Image.open(t2)).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        t1_features = model.encode_image(t1_input)\n",
        "\n",
        "        if is_multimodal:\n",
        "            t2_features = model.encode_text(t2_input)\n",
        "        else:\n",
        "            t2_features = model.encode_image(t2_input)\n",
        "\n",
        "        t1_features /= t1_features.norm(dim=-1, keepdim=True)\n",
        "        t2_features /= t2_features.norm(dim=-1, keepdim=True)\n",
        "        similarity = (t1_features @ t2_features.T)\n",
        "\n",
        "    return similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "%cd drive/MyDrive/genai_proj/instruct-pix2pix/clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3-8w42PM-QV",
        "outputId": "4ceb94ec-6b73-4d36-b790-67d08a77e737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7.1  condacolab_install.log  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "/content/drive/MyDrive/genai_proj/instruct-pix2pix/clip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "%ls input_image\n",
        "%ls output_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlhcmACANI4r",
        "outputId": "89d11045-759b-4160-fd77-9941c4fcfae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34minput_image\u001b[0m/  \u001b[01;34moutput_image\u001b[0m/\n",
            "1_a.jpeg  1_b.jpeg  2.jpeg  3.jpeg  4.jpeg\n",
            "output1_a.jpeg  output1_b.jpeg  output2.jpeg  output3.jpeg  output4.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Image\n",
        "\n",
        "INPUT_PATH = \"input_image/\"\n",
        "OUTPUT_PATH = \"output_image/\"\n",
        "\n",
        "png_paths = [\"1_a.jpeg\", \"1_b.jpeg\", \"2.jpeg\", \"3.jpeg\", \"4.jpeg\"]\n",
        "input_images = []\n",
        "output_images = []\n",
        "\n",
        "for i in range(0, len(png_paths)):\n",
        "    input_images.append(f\"{INPUT_PATH}{png_paths[i]}\")\n",
        "    output_images.append(f\"{OUTPUT_PATH}output{png_paths[i]}\")\n",
        "\n",
        "\n",
        "for i in range(0, len(png_paths)):\n",
        "    print(calculate_clip(input_images[i], output_images[i], False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xjp03lHIM4s",
        "outputId": "2ea48722-24bd-42cf-f18b-a30911d95099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8687]], device='cuda:0', dtype=torch.float16)\n",
            "tensor([[0.6885]], device='cuda:0', dtype=torch.float16)\n",
            "tensor([[0.7236]], device='cuda:0', dtype=torch.float16)\n",
            "tensor([[0.8599]], device='cuda:0', dtype=torch.float16)\n",
            "tensor([[0.6230]], device='cuda:0', dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using diffusers pipelines for CLIP and DinoV2 scores\n",
        "- Note, load specific pretrained CLIP on which stable diffusion is trained\n",
        "- Also, modified from https://medium.com/aimonks/clip-vs-dinov2-in-image-similarity-6fa5aa7ed8c6"
      ],
      "metadata": {
        "id": "VCgfZHI6YLLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers Pillow torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03NHYYJmdHy6",
        "outputId": "451569e2-581d-40d2-a604-3635805cbe88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, CLIPModel\n",
        "import torch.nn as nn\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "5mOs11wMao42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip_processor = AutoProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
        "\n",
        "def get_clipI(i1_path, i2_path, device=device, processor=clip_processor, model=clip_model):\n",
        "    #Extract features from image1\n",
        "    with torch.no_grad():\n",
        "        inputs1 = processor(images=Image.open(i1_path), return_tensors=\"pt\").to(device)\n",
        "        image_features1 = model.get_image_features(**inputs1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs2 = processor(images=Image.open(i2_path), return_tensors=\"pt\").to(device)\n",
        "        image_features2 = model.get_image_features(**inputs2)\n",
        "\n",
        "    #Compute their cosine similarity and convert it into a score between 0 and 1\n",
        "    cos = nn.CosineSimilarity(dim=0)\n",
        "    sim = cos(image_features1[0],image_features2[0]).item()\n",
        "    sim = (sim+1)/2\n",
        "    print('Similarity:', sim)\n",
        "    return sim"
      ],
      "metadata": {
        "id": "u4aztkZYKd2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dino_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
        "dino_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
        "\n",
        "def get_dinoV2(i1_path, i2_path, device=device, processor=dino_processor, model=dino_model):\n",
        "    with torch.no_grad():\n",
        "        inputs1 = processor(images=Image.open(i1_path), return_tensors=\"pt\").to(device)\n",
        "        outputs1 = model(**inputs1)\n",
        "        image_features1 = outputs1.last_hidden_state\n",
        "        image_features1 = image_features1.mean(dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs2 = processor(images=Image.open(i2_path), return_tensors=\"pt\").to(device)\n",
        "        outputs2 = model(**inputs2)\n",
        "        image_features2 = outputs2.last_hidden_state\n",
        "        image_features2 = image_features2.mean(dim=1)\n",
        "\n",
        "    cos = nn.CosineSimilarity(dim=0)\n",
        "    sim = cos(image_features1[0],image_features2[0]).item()\n",
        "    sim = (sim+1)/2\n",
        "    print('Similarity:', sim)\n",
        "    return sim"
      ],
      "metadata": {
        "id": "q7eWqv39aPrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktxy2v7vIvJi",
        "outputId": "4e216a4a-3255-40cd-f0f5-6a90f7e8355b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.jpeg  15.jpeg  1_a.jpg  21.jpeg  26.jpeg  2_b.jpg  31.jpeg  37.jpeg  41.jpg  46.jpg  8.jpeg\n",
            "11.jpeg  16.jpeg  1_b.jpg  22.jpeg  27.jpeg  2_c.jpg  33.jpeg  38.jpg   42.jpg  4.jpeg  9.jpeg\n",
            "12.jpeg  17.jpeg  1_c.jpg  23.jpeg  28.jpeg  2_d.jpg  34.jpeg  39.jpg   43.jpg  5.jpeg\n",
            "13.jpeg  18.jpeg  1.jpeg   24.jpeg  29.jpeg  2.jpeg   35.jpeg  3.jpeg   44.jpg  6.jpeg\n",
            "14.jpeg  19.jpeg  20.jpeg  25.jpeg  2_a.jpg  30.jpeg  36.jpeg  40.jpg   45.jpg  7.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls output_baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUsBwg6UJJyx",
        "outputId": "4a322dd5-e8d4-40da-f5e7-349ce50d1aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.png  1_a.png  21.png  33.png  3.png   46.png  5.png  8.png\n",
            "15.png  1_b.png  2.png   36.png  41.png  4.png   7.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls imgs_edited"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wle8oja0T8U1",
        "outputId": "32212a92-f87c-4d47-ba16-04541439cbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_a.jpg  1_b.jpg  21.jpeg  2.jpeg  36.jpeg  3.jpeg  41.jpg  46.jpg  7.jpeg  prompts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = \"dataset/\"\n",
        "OUTPUT_PATH = \"output_baseline/\"\n",
        "\n",
        "in_paths = [\"1_a.jpg\",  \"1_b.jpg\",  \"21.jpeg\",  \"2.jpeg\",  \"36.jpeg\",  \"3.jpeg\",  \"41.jpg\",  \"46.jpg\",  \"7.jpeg\"]\n",
        "out_paths = [\"1_a.png\",  \"1_b.png\",  \"21.png\",  \"2.png\",  \"36.png\",  \"3.png\",  \"41.png\",  \"46.png\",  \"7.png\"]\n",
        "input_images = []\n",
        "output_images = []\n",
        "\n",
        "for i in range(0, len(in_paths)):\n",
        "    input_images.append(f\"{INPUT_PATH}{in_paths[i]}\")\n",
        "    output_images.append(f\"{OUTPUT_PATH}{out_paths[i]}\")\n",
        "\n",
        "\n",
        "clip_total = 0\n",
        "dino_total = 0\n",
        "for i in range(0, len(in_paths)):\n",
        "    clip_total += get_clipI(input_images[i], output_images[i])\n",
        "    dino_total += get_dinoV2(input_images[i], output_images[i])\n",
        "\n",
        "print(clip_total/len(in_paths))\n",
        "print(dino_total/len(in_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4fQ5Hn4dfkU",
        "outputId": "7db85eb8-5743-496e-dcf1-b9f86436a83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.9463466703891754\n",
            "Similarity: 0.9937996566295624\n",
            "Similarity: 0.8090856969356537\n",
            "Similarity: 0.6621357798576355\n",
            "Similarity: 0.9793371856212616\n",
            "Similarity: 0.9882122874259949\n",
            "Similarity: 0.9554187655448914\n",
            "Similarity: 0.9804982841014862\n",
            "Similarity: 0.8865485787391663\n",
            "Similarity: 0.960048258304596\n",
            "Similarity: 0.8895609378814697\n",
            "Similarity: 0.950719952583313\n",
            "Similarity: 0.8307322263717651\n",
            "Similarity: 0.7203241735696793\n",
            "Similarity: 0.7651555240154266\n",
            "Similarity: 0.8155746459960938\n",
            "Similarity: 0.9890547692775726\n",
            "Similarity: 0.9931381046772003\n",
            "0.8945822616418203\n",
            "0.8960501270161735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = \"dataset/\"\n",
        "OUTPUT_PATH = \"imgs_edited/\"\n",
        "\n",
        "in_paths = [\"1_a.jpg\",  \"1_b.jpg\",  \"21.jpeg\",  \"2.jpeg\",  \"36.jpeg\",  \"3.jpeg\",  \"41.jpg\",  \"46.jpg\",  \"7.jpeg\"]\n",
        "out_paths = [\"1_a.jpg\",  \"1_b.jpg\",  \"21.jpeg\",  \"2.jpeg\",  \"36.jpeg\",  \"3.jpeg\",  \"41.jpg\",  \"46.jpg\",  \"7.jpeg\"]\n",
        "input_images = []\n",
        "output_images = []\n",
        "\n",
        "for i in range(0, len(in_paths)):\n",
        "    input_images.append(f\"{INPUT_PATH}{in_paths[i]}\")\n",
        "    output_images.append(f\"{OUTPUT_PATH}{out_paths[i]}\")\n",
        "\n",
        "clip_total = 0\n",
        "dino_total = 0\n",
        "for i in range(0, len(in_paths)):\n",
        "    clip_total += get_clipI(input_images[i], output_images[i])\n",
        "    dino_total += get_dinoV2(input_images[i], output_images[i])\n",
        "\n",
        "print(clip_total/len(in_paths))\n",
        "print(dino_total/len(in_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jTnpyIhMXxB",
        "outputId": "d894bb11-c731-4de5-dba4-3322398f2b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.9093898236751556\n",
            "Similarity: 0.9690873026847839\n",
            "Similarity: 0.9542901515960693\n",
            "Similarity: 0.9268201589584351\n",
            "Similarity: 0.9300181865692139\n",
            "Similarity: 0.9161568880081177\n",
            "Similarity: 0.9189943969249725\n",
            "Similarity: 0.9323628544807434\n",
            "Similarity: 0.8749442100524902\n",
            "Similarity: 0.8393747806549072\n",
            "Similarity: 0.9176546633243561\n",
            "Similarity: 0.9237892031669617\n",
            "Similarity: 0.8879525661468506\n",
            "Similarity: 0.7527952492237091\n",
            "Similarity: 0.9682963490486145\n",
            "Similarity: 0.9486328959465027\n",
            "Similarity: 0.8996129035949707\n",
            "Similarity: 0.9351735711097717\n",
            "0.9179059167702993\n",
            "0.9049103226926591\n"
          ]
        }
      ]
    }
  ]
}